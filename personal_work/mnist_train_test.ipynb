{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpxWb-2fnaHO",
        "outputId": "3948dee7-baaf-4d27-c620-bd4b8d4745ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 33s 46ms/step - loss: 0.4853 - accuracy: 0.8454 - val_loss: 0.0492 - val_accuracy: 0.9834\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 20s 43ms/step - loss: 0.1887 - accuracy: 0.9421 - val_loss: 0.0343 - val_accuracy: 0.9887\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.1533 - accuracy: 0.9550 - val_loss: 0.0317 - val_accuracy: 0.9884\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 0.1297 - accuracy: 0.9610 - val_loss: 0.0293 - val_accuracy: 0.9903\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 0.1167 - accuracy: 0.9642 - val_loss: 0.0304 - val_accuracy: 0.9896\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1089 - accuracy: 0.9678 - val_loss: 0.0248 - val_accuracy: 0.9922\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 0.1016 - accuracy: 0.9697 - val_loss: 0.0245 - val_accuracy: 0.9919\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.0958 - accuracy: 0.9718 - val_loss: 0.0231 - val_accuracy: 0.9923\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 0.0891 - accuracy: 0.9732 - val_loss: 0.0216 - val_accuracy: 0.9928\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.0855 - accuracy: 0.9749 - val_loss: 0.0221 - val_accuracy: 0.9925\n",
            "Test loss: 0.022067369893193245\n",
            "Test accuracy: 0.9925000071525574\n"
          ]
        }
      ],
      "source": [
        "# Importation des bibliothèques nécessaires\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Chargement des données MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisation des données\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Redimensionnement des données pour qu'elles correspondent au format attendu par les couches Conv2D\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# Création du modèle\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compilation du modèle\n",
        "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Create an ImageDataGenerator object\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "    zoom_range = 0.1, # Randomly zoom image\n",
        "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        ")\n",
        "\n",
        "# Compute quantities required for feature-wise normalization\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Entraînement du modèle\n",
        "model.fit(datagen.flow(x_train, y_train, batch_size=128),\n",
        "          validation_data=(x_test, y_test),\n",
        "          epochs=10, verbose=1)\n",
        "\n",
        "# Évaluation du modèle\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "canvas_html = \"\"\"\n",
        "<canvas width=%d height=%d></canvas>\n",
        "<button>Finish</button>\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "ctx.fillStyle = \"#FFFFFF\";\n",
        "ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
        "ctx.lineWidth = %d\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "  mouse.x = e.pageX - this.offsetLeft\n",
        "  mouse.y = e.pageY - this.offsetTop\n",
        "})\n",
        "canvas.onmousedown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  canvas.addEventListener('mousemove', onPaint)\n",
        "}\n",
        "canvas.onmouseup = ()=>{\n",
        "  canvas.removeEventListener('mousemove', onPaint)\n",
        "}\n",
        "var onPaint = ()=>{\n",
        "  ctx.rect(Math.floor(mouse.x/%d)*%d, Math.floor(mouse.y/%d)*%d, %d, %d)\n",
        "  ctx.stroke()\n",
        "}\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/png'))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def draw(filename='drawing.png', w=400, h=200, line_width=1):\n",
        "  display(HTML(canvas_html % (w, h, line_width, line_width, line_width, line_width, line_width, line_width, line_width)))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return len(binary)"
      ],
      "metadata": {
        "id": "Mjbxkkl1tS1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "\n",
        "def preprocess_image(img):\n",
        "    # Convert the image to grayscale\n",
        "    img = img.convert(\"L\")\n",
        "\n",
        "    # Resize the image\n",
        "    img = img.resize((28, 28), Image.NEAREST)\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    img = np.array(img)\n",
        "\n",
        "    # Invert the colors\n",
        "    img = 255 - img\n",
        "\n",
        "    # Scale the image data to the range [0, 1]\n",
        "    img = img / 255.0\n",
        "\n",
        "    # Reshape the image data for use in the model\n",
        "    img = img.reshape(1, 28, 28, 1)\n",
        "\n",
        "    return img\n",
        "\n",
        "def predict_image(filename):\n",
        "    # Load the image\n",
        "    img = Image.open(filename)\n",
        "\n",
        "    # Preprocess the image\n",
        "    img = preprocess_image(img)\n",
        "\n",
        "    # Use the model to make a prediction\n",
        "    predictions = model.predict(img)\n",
        "\n",
        "    # Get the top 3 predictions and their confidence levels\n",
        "    top3_predictions = np.argsort(predictions[0])[-3:][::-1]\n",
        "    top3_confidences = predictions[0][top3_predictions]\n",
        "\n",
        "    return list(zip(top3_predictions, top3_confidences))"
      ],
      "metadata": {
        "id": "Ul7J0CCA5lt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "for i in range(20):\n",
        "    filename = f\"test_{i}.png\"\n",
        "    draw(filename=filename, w=400, h=400, line_width=10)\n",
        "\n",
        "    predicted_digit = predict_image(filename)\n",
        "    print(f\"Predictions for {filename}:\")\n",
        "    for i, (digit, confidence) in enumerate(predicted_digit):\n",
        "        print(f\"  #{i+1}: Digit {digit} with confidence {confidence * 100:.2f}%\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            print(\"If the model is incorrect, please enter the correct label: \", end='\\n')\n",
        "            correct_label = int(input())\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"That's not a valid number. Please enter again.\")\n",
        "\n",
        "    image = Image.open(filename)\n",
        "\n",
        "    image = preprocess_image(image)\n",
        "\n",
        "    # Add the new example to the training data\n",
        "    x_train = np.concatenate([x_train, image])\n",
        "    y_train = np.concatenate([y_train, [correct_label]])\n",
        "\n",
        "    clear_output(wait=True)\n",
        "\n",
        "# After collecting all the new data, retrain the model on the updated data\n",
        "# You might want to use a smaller learning rate for this\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "# Save the model so that the training last :\n",
        "model.save('model_after_training.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "HdS7_5WGtX7H",
        "outputId": "b7a3c520-d32e-46c4-bc45-f403a809d469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<canvas width=400 height=400></canvas>\n",
              "<button>Finish</button>\n",
              "<script>\n",
              "var canvas = document.querySelector('canvas')\n",
              "var ctx = canvas.getContext('2d')\n",
              "ctx.fillStyle = \"#FFFFFF\";\n",
              "ctx.fillRect(0, 0, canvas.width, canvas.height);\n",
              "ctx.lineWidth = 10\n",
              "var button = document.querySelector('button')\n",
              "var mouse = {x: 0, y: 0}\n",
              "canvas.addEventListener('mousemove', function(e) {\n",
              "  mouse.x = e.pageX - this.offsetLeft\n",
              "  mouse.y = e.pageY - this.offsetTop\n",
              "})\n",
              "canvas.onmousedown = ()=>{\n",
              "  ctx.beginPath()\n",
              "  ctx.moveTo(mouse.x, mouse.y)\n",
              "  canvas.addEventListener('mousemove', onPaint)\n",
              "}\n",
              "canvas.onmouseup = ()=>{\n",
              "  canvas.removeEventListener('mousemove', onPaint)\n",
              "}\n",
              "var onPaint = ()=>{\n",
              "  ctx.rect(Math.floor(mouse.x/10)*10, Math.floor(mouse.y/10)*10, 10, 10)\n",
              "  ctx.stroke()\n",
              "}\n",
              "var data = new Promise(resolve=>{\n",
              "  button.onclick = ()=>{\n",
              "    resolve(canvas.toDataURL('image/png'))\n",
              "  }\n",
              "})\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "Predictions for test_5.png:\n",
            "  #1: Digit 9 with confidence 95.88%\n",
            "  #2: Digit 4 with confidence 1.52%\n",
            "  #3: Digit 3 with confidence 1.27%\n",
            "If the model is incorrect, please enter the correct label: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('model_after_training.h5')\n",
        "\n",
        "for i in range(20):\n",
        "    filename = f\"test_{i}.png\"\n",
        "    draw(filename=filename, w=400, h=400, line_width=10)\n",
        "\n",
        "    predicted_digit = predict_image(filename)\n",
        "    print(f\"Predictions for {filename}:\")\n",
        "    for i, (digit, confidence) in enumerate(predicted_digit):\n",
        "        print(f\"  #{i+1}: Digit {digit} with confidence {confidence * 100:.2f}%\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            print(\"If the model is incorrect, please enter the correct label: \", end='\\n')\n",
        "            correct_label = int(input())\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"That's not a valid number. Please enter again.\")\n",
        "\n",
        "    image = Image.open(filename)\n",
        "\n",
        "    image = preprocess_image(image)\n",
        "\n",
        "    # Add the new example to the training data\n",
        "    x_train = np.concatenate([x_train, image])\n",
        "    y_train = np.concatenate([y_train, [correct_label]])\n",
        "\n",
        "    clear_output(wait=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g9eBULli_XAn",
        "outputId": "9e740841-3944-4f60-9e02-d1d0acdbe9df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "No file or directory found at model_after_training.h5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ce52a5b0a623>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_after_training.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at model_after_training.h5"
          ]
        }
      ]
    }
  ]
}